# Spotify_PySpark_ETL_pipeline

<strong>Project Overview:</strong> <br>
Designed a end-to-end ETL pipeline, which integrates data from Spotify through REST API leveraging the <i>spotipy</i> library into Data Warehouse in Snowflake. The entire process has been automated using different tools like AWS Cloudwatch and snowpipe. The aim of this project was to get myself familiarized with Apache Spark and Databricks leveraging cloud. Utilized AWS services like S3, Lambda, Glue to build the data integration and transformation layers of the pipeline. 

<strong>Tech Stack:</strong> <br>
Tools: Databricks, Apache Spark, Snowpipe<br>
Cloud: AWS - Glue, S3, Lambda, CloudWatch<br>
Database: Snowflake, Dataframe, RDD<br>
Language: Python, PySpark, Spotipy, pandas<br>
File type: JSON, CSV, Apache Parquet

Project Architecture:<br>
![Architecture](https://github.com/ShwetSaoji/Spotify_PySpark_ETL_pipeline/assets/112597837/04e90221-edc2-4716-9b27-9d124fc84c76)


